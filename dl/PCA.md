# PCA 主成分分析
## 作用
将一组高维数据变换为一组低维数据，同时保证数据的主要特征得到保留 是一种主要的降维方法

## 数学理解
一个高维（N维）的数据点集合S，选取一个低维（M维）的超平面P将S投影在P上，使得S在P上的投影点集合S‘在M维上最大保持原有数据的特异性（方差最大的方向作为主要特征）

## 样例理解
该部分内容from: http://www.360doc.com/content/13/1124/02/9482_331688889.shtml
#### 首先基变换可由矩阵表示：
新（单位）基按行排成矩阵A
要变换的向量按列排成矩阵B
A x B即为各向量按列排布得到的矩阵
#### sample
对于得到的一个二维矩阵A，先将其每个字段内所有值都减去字段均值，使数据点中心为原点
### 我们要使：

*  降维后方差最大-最大保留特征

*  降维后协方差为零-方向正交

#### 至此可以引出---协方差矩阵：
恰好满足对角线为方差，而除对角线外均为协方差的矩阵 C = X X’
而我们要做的就是得到这样的协方差矩阵--对角的协方差矩阵D

#### 我们的任务变成
找到矩阵P 有 P X = Y 
而 Y Y' = D
P即为我们要找的基组成的矩阵

#### 如何找到P呢？
从D = PCP‘入手
实际就是C的对角化问题

而C是实对称矩阵，n维实对称矩阵一定可以找到n个单位正交向量，组成矩阵P并将其对角化（参考线性代数）
因此P可求出，这时取lamda中占主要部分的组成新的矩阵PP，再用PP x X即可得到新的降维后的数据组成的矩阵

## 实际实现
在用Python实际实现时 可以：
* 调用scikit-learn库
参考http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html

* 用numpy手动实现
参考http://www.cnblogs.com/lzllovesyl/p/5235137.html

